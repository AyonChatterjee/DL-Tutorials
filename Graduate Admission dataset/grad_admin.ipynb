{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcac056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fbd3e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset\\Admission_Predict_Ver1.1.csv\")\n",
    "df.head()\n",
    "\n",
    "# Using the second csv file because it is more updated version bro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17aee5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Finding some missing or null values bro\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a440bf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a5a358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Serial No.'] , inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cdb28a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0 : 7]\n",
    "y = df.iloc[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e229e626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f932d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44924ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.3,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1967249b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>330</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>299</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>317</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>307</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>329</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>306</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>302</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "5          330          115                  5  4.5   3.0  9.34         1\n",
       "116        299          102                  3  4.0   3.5  8.62         0\n",
       "45         322          110                  5  5.0   4.0  9.10         1\n",
       "16         317          107                  3  4.0   3.0  8.70         0\n",
       "462        307          105                  4  3.0   3.0  7.94         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "106        329          111                  4  4.5   4.5  9.18         1\n",
       "270        306          105                  2  2.5   3.0  8.22         1\n",
       "348        302           99                  1  2.0   2.0  7.25         0\n",
       "435        309          105                  2  2.5   4.0  7.68         0\n",
       "102        314          106                  2  4.0   3.5  8.25         0\n",
       "\n",
       "[350 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e84825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      0.90\n",
       "116    0.56\n",
       "45     0.88\n",
       "16     0.66\n",
       "462    0.62\n",
       "       ... \n",
       "106    0.87\n",
       "270    0.72\n",
       "348    0.57\n",
       "435    0.55\n",
       "102    0.62\n",
       "Name: Chance of Admit , Length: 350, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad4360f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc556c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78723404, 0.82142857, 1.        , ..., 0.42857143, 0.81410256,\n",
       "        1.        ],\n",
       "       [0.12765957, 0.35714286, 0.5       , ..., 0.57142857, 0.58333333,\n",
       "        0.        ],\n",
       "       [0.61702128, 0.64285714, 1.        , ..., 0.71428571, 0.73717949,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.19148936, 0.25      , 0.        , ..., 0.14285714, 0.14423077,\n",
       "        0.        ],\n",
       "       [0.34042553, 0.46428571, 0.25      , ..., 0.71428571, 0.28205128,\n",
       "        0.        ],\n",
       "       [0.44680851, 0.5       , 0.25      , ..., 0.57142857, 0.46474359,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90cbb5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87234043, 0.85714286, 0.75      , ..., 0.57142857, 0.87820513,\n",
       "        1.        ],\n",
       "       [0.44680851, 0.57142857, 0.75      , ..., 0.71428571, 0.71794872,\n",
       "        1.        ],\n",
       "       [0.46808511, 0.46428571, 0.25      , ..., 0.28571429, 0.2724359 ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.65957447, 0.75      , 0.75      , ..., 0.71428571, 0.63782051,\n",
       "        0.        ],\n",
       "       [0.40425532, 0.42857143, 0.5       , ..., 0.71428571, 0.41346154,\n",
       "        0.        ],\n",
       "       [0.40425532, 0.5       , 0.5       , ..., 1.        , 0.56730769,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b14da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e81e7182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chatt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7 , activation='relu',input_dim = 7)) # 1st hidden layer\n",
    "model.add(Dense(7 , activation='relu')) # 2nd hidden layer \n",
    "model.add(Dense(1, activation='linear')) # output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee329b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de8f126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error' , optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6faf16a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 7)\n",
      "(350,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff058edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58c53871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0028 - val_loss: 0.9218\n",
      "Epoch 2/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8203 - val_loss: 0.7481\n",
      "Epoch 3/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6541 - val_loss: 0.5970\n",
      "Epoch 4/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5053 - val_loss: 0.4538\n",
      "Epoch 5/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4050 - val_loss: 0.3285\n",
      "Epoch 6/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3155 - val_loss: 0.2306\n",
      "Epoch 7/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2249 - val_loss: 0.1554\n",
      "Epoch 8/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1521 - val_loss: 0.0995\n",
      "Epoch 9/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1010 - val_loss: 0.0587\n",
      "Epoch 10/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0624 - val_loss: 0.0322\n",
      "Epoch 11/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0335 - val_loss: 0.0184\n",
      "Epoch 12/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0223 - val_loss: 0.0131\n",
      "Epoch 13/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0150 - val_loss: 0.0120\n",
      "Epoch 14/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0159 - val_loss: 0.0116\n",
      "Epoch 15/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 16/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0119 - val_loss: 0.0103\n",
      "Epoch 17/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0124 - val_loss: 0.0096\n",
      "Epoch 18/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 19/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 20/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 21/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 22/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 23/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 24/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 25/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 26/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 27/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 28/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 29/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 30/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 31/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 32/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 33/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 34/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 35/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 36/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 37/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 38/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 39/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0076 - val_loss: 0.0067\n",
      "Epoch 40/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 41/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 42/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 43/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 44/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 45/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 46/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 47/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 48/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 49/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 50/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 51/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 52/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 53/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 54/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 55/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 56/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 57/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 58/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 59/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 60/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 61/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 62/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 63/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 64/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 65/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 66/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 67/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 68/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 69/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 70/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 71/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 72/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 73/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 74/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 75/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 76/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 77/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 78/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 79/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 80/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 81/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 82/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 83/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 84/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 85/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 86/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 87/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 88/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 89/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 90/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 91/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 92/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 93/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 94/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 95/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 96/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 97/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 98/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 99/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 100/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 101/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 102/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 103/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 104/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 105/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 106/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 107/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 108/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 109/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 110/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 111/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 112/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 113/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 114/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 115/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 116/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 117/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 118/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 119/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 120/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 121/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 122/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 123/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 124/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 125/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 126/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 127/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 128/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 129/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 130/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 131/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 132/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 133/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 134/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 135/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 136/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 137/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 138/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 139/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 140/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 141/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 142/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 143/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 144/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 145/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 146/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 147/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 148/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 149/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 150/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 151/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 152/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 153/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 154/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 155/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 156/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 157/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 158/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 159/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 160/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 161/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 162/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 163/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 164/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 165/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 166/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 167/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 168/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 169/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 170/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 171/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 172/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 173/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 174/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 175/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 176/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 177/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 178/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 179/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 180/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 181/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 182/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 183/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 184/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 185/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 186/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 187/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 188/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 189/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 190/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 191/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 192/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 193/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 194/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 195/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 196/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 197/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 198/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 199/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 200/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0038 - val_loss: 0.0029\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train,epochs=200, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a1d594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7187c669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8117630885767386"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5e255b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
